{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda484d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGIN_DATA = \"origin_data\"\n",
    "DATA_CSV = \"origin_data_csv\"\n",
    "LOGS = \"logs\"\n",
    "MATCH = \"Z:\"\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import wfdb                                      # 讀取 WFDB header / record :contentReference[oaicite:4]{index=4}\n",
    "from pathlib import Path                         # 物件導向檔案操作 :contentReference[oaicite:5]{index=5}\n",
    "from datetime import datetime, timedelta, date, time\n",
    "from tqdm import tqdm                            # 進度列（可省略）\n",
    "import logging, os                               # 紀錄檔與系統路徑\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "from typing import List, Optional, Tuple,Set\n",
    "from  tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "try:\n",
    "    alive_yuran = pd.read_csv(\"./experiment_data_from_yuran/alive_42731_withHRV.csv\")\n",
    "    dead_yuran = pd.read_csv(\"./experiment_data_from_yuran/dead_42731_withHRV.csv\")\n",
    "\n",
    "    alive_set = set(alive_yuran['SUBJECT_ID'].to_list())\n",
    "    dead_set = set(dead_yuran[\"SUBJECT_ID\"].to_list())\n",
    "\n",
    "    total_set = alive_set | dead_set\n",
    "\n",
    "    mort_stage2_filtered = pd.read_csv(os.path.join(LOGS, \"mort_stage2_filtered.csv\"))\n",
    "    surv_stage2_filtered = pd.read_csv(os.path.join(LOGS, \"surv_stage2_filtered.csv\"))\n",
    "\n",
    "    mort_set = set(mort_stage2_filtered['SUBJECT_ID'].to_list())\n",
    "    surv_set = set(surv_stage2_filtered['SUBJECT_ID'].to_list())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6d704d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting wave_id: 100%|██████████| 1450/1450 [06:41<00:00,  3.61it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_wave_id(row):\n",
    "    header_path = os.path.join(MATCH, row['PREFIX'], row['FOLDER'], row['HEADER'])\n",
    "    \n",
    "    try:\n",
    "        hdr = wfdb.rdheader(header_path, rd_segments=True)\n",
    "        for seg_name in hdr.seg_name:\n",
    "            if seg_name == '~':\n",
    "                continue\n",
    "            wave_id = seg_name.split(\"_\")[0]\n",
    "            if re.fullmatch(r'\\d+', wave_id):\n",
    "                return wave_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {header_path}: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def read_wave_id(df: pd.DataFrame, max_workers=8) -> pd.DataFrame:\n",
    "    rows = list(df.iterrows())\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        wave_ids = list(tqdm(\n",
    "            executor.map(lambda x: extract_wave_id(x[1]), rows),\n",
    "            total=len(rows),\n",
    "            desc=\"Extracting wave_id\"\n",
    "        ))\n",
    "\n",
    "    df['wave_id'] = wave_ids\n",
    "    return df\n",
    "\n",
    "# mort_stage2_filtered_with_wave_id=read_wave_id(mort_stage2_filtered)\n",
    "# print(mort_stage2_filtered_with_wave_id.info())\n",
    "\n",
    "# mort_stage2_filtered_with_wave_id = mort_stage2_filtered_with_wave_id.rename(columns={\"AGE_YEARS\":\"age\"})\n",
    "# mort_stage2_filtered_with_wave_id.to_csv(os.path.join(LOGS,\"mort_stage2_filtered_with_wave_id.csv\"),index = False)\n",
    "\n",
    "surv_stage2_filtered_with_wave_id = read_wave_id(surv_stage2_filtered)\n",
    "surv_stage2_filtered_with_wave_id = surv_stage2_filtered_with_wave_id.rename(columns={\"AGE_YEARS\":\"age\"})\n",
    "surv_stage2_filtered_with_wave_id.to_csv(os.path.join(LOGS,\"surv_stage2_filtered_with_wave_id.csv\"),index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ca469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有 96 組 row 在兩個表格都出現。\n",
      "dead_yuran 有、mort_final_same 沒有的 row：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_102568\\448686293.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mort_final_same['wave_id'] = mort_final_same['wave_id'].astype(str).str.strip()\n"
     ]
    }
   ],
   "source": [
    "# Mort: ['SUBJECT_ID', 'HADM_ID','wave_id'] 嚴格交叉比對\n",
    "\n",
    "cols = ['SUBJECT_ID', 'HADM_ID','wave_id']\n",
    "mort_final_same = mort_stage2_filtered_with_wave_id[mort_stage2_filtered_with_wave_id['SUBJECT_ID'].isin(dead_set & mort_set)]\n",
    "dead_yuran = dead_yuran[dead_yuran['SUBJECT_ID'].isin(dead_set & mort_set)]\n",
    "\n",
    "# 前處理\n",
    "\n",
    "dead_yuran['wave_id'] = dead_yuran['wave_id'].astype(str).str.strip()\n",
    "mort_final_same['wave_id'] = mort_final_same['wave_id'].astype(str).str.strip()\n",
    "\n",
    "\n",
    "# 1. 建立每組 row 的 tuple set\n",
    "set_mort = set(tuple(row) for row in mort_final_same[cols].values)\n",
    "set_yuran = set(tuple(row) for row in dead_yuran[cols].values)\n",
    "\n",
    "# 2. 找兩組有交集（完全重複的 row）\n",
    "common = set_mort & set_yuran\n",
    "\n",
    "print(f\"共有 {len(common)} 組 row 在兩個表格都出現。\")\n",
    "# if common:\n",
    "#     print(\"重複的 row：\")\n",
    "#     for t in common:\n",
    "#         print(t)\n",
    "# else:\n",
    "#     print(\"沒有任何 row 同時存在兩表。\")\n",
    "\n",
    "# 3. 若要找 dead_yuran 中有哪些 row 沒有出現在 mort_final_same：\n",
    "only_in_yuran = set_yuran - set_mort\n",
    "print(\"dead_yuran 有、mort_final_same 沒有的 row：\")\n",
    "for t in only_in_yuran:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fa0741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有 361 組 row 在兩個表格都出現。\n",
      "alive_yuran 有、surv_final_same 沒有的 row：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_102568\\2060540429.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surv_final_same['wave_id'] = surv_final_same['wave_id'].astype(str).str.strip()\n"
     ]
    }
   ],
   "source": [
    "# Surv: ['SUBJECT_ID', 'HADM_ID','wave_id'] 嚴格交叉比對\n",
    "\n",
    "cols = ['SUBJECT_ID', 'HADM_ID','wave_id']\n",
    "surv_final_same = surv_stage2_filtered_with_wave_id[surv_stage2_filtered_with_wave_id['SUBJECT_ID'].isin(alive_set & surv_set)]\n",
    "alive_yuran = alive_yuran[alive_yuran['SUBJECT_ID'].isin(alive_set & surv_set)]\n",
    "\n",
    "# 前處理\n",
    "\n",
    "alive_yuran['wave_id'] = alive_yuran['wave_id'].astype(str).str.strip()\n",
    "surv_final_same['wave_id'] = surv_final_same['wave_id'].astype(str).str.strip()\n",
    "\n",
    "# 1. 建立每組 row 的 tuple set\n",
    "set_surv = set(tuple(row) for row in surv_final_same[cols].values)\n",
    "set_yuran = set(tuple(row) for row in alive_yuran[cols].values)\n",
    "\n",
    "common = set_surv & set_yuran\n",
    "\n",
    "print(f\"共有 {len(common)} 組 row 在兩個表格都出現。\")\n",
    "\n",
    "only_in_yuran = set_yuran - set_surv\n",
    "print(\"alive_yuran 有、surv_final_same 沒有的 row：\")\n",
    "for t in only_in_yuran:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e7e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2793 entries, 0 to 2792\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   SUBJECT_ID      2793 non-null   int64         \n",
      " 1   ECG_DATETIME    2793 non-null   datetime64[ns]\n",
      " 2   HADM_ID         2793 non-null   int64         \n",
      " 3   ICD9_CODE       2793 non-null   object        \n",
      " 4   ADMITTIME       2793 non-null   datetime64[ns]\n",
      " 5   DISCHTIME       2793 non-null   datetime64[ns]\n",
      " 6   DEATHTIME       0 non-null      datetime64[ns]\n",
      " 7   ECG_DATETIME_y  2793 non-null   object        \n",
      " 8   GENDER          2793 non-null   object        \n",
      " 9   DOB             2793 non-null   datetime64[ns]\n",
      " 10  wave_id         2793 non-null   int64         \n",
      " 11  age             2793 non-null   int64         \n",
      " 12  death           2793 non-null   int64         \n",
      "dtypes: datetime64[ns](5), int64(5), object(3)\n",
      "memory usage: 283.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 591 entries, 0 to 590\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   SUBJECT_ID      591 non-null    int64         \n",
      " 1   ECG_DATETIME    591 non-null    datetime64[ns]\n",
      " 2   HADM_ID         591 non-null    int64         \n",
      " 3   ICD9_CODE       591 non-null    object        \n",
      " 4   ADMITTIME       591 non-null    datetime64[ns]\n",
      " 5   DISCHTIME       591 non-null    datetime64[ns]\n",
      " 6   DEATHTIME       591 non-null    datetime64[ns]\n",
      " 7   ECG_DATETIME_y  591 non-null    object        \n",
      " 8   GENDER          591 non-null    object        \n",
      " 9   DOB             591 non-null    datetime64[ns]\n",
      " 10  wave_id         591 non-null    int64         \n",
      " 11  age             591 non-null    int64         \n",
      " 12  death           591 non-null    int64         \n",
      "dtypes: datetime64[ns](5), int64(5), object(3)\n",
      "memory usage: 60.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from typing import List, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _safe_literal(val: str):\n",
    "    \"\"\"安全地轉為 Python 物件；失敗就回 None。\"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _parse_icd9(val: str) -> List[int]:\n",
    "    \"\"\"將 '[1,2,3]' → [1,2,3]；不合法或空值回 [].\"\"\"\n",
    "    if pd.isna(val) or val.strip() in (\"\", \"[]\"):\n",
    "        return []\n",
    "    items = _safe_literal(val)\n",
    "    if items is None:\n",
    "        return []\n",
    "    return [int(x) for x in items]\n",
    "\n",
    "def _parse_ecg_list(val: str) -> List[pd.Timestamp]:\n",
    "    \"\"\"將 '[2160/7/5 18:27,...]' 轉 List[pd.Timestamp]；空值回 [].\"\"\"\n",
    "    if pd.isna(val) or val.strip() in (\"\", \"[]\"):\n",
    "        return []\n",
    "    # 去掉頭尾中括號再以逗號切\n",
    "    ts_list = val.strip(\"[]\").split(\",\")\n",
    "    return [pd.to_datetime(ts.strip(), errors=\"coerce\") for ts in ts_list]\n",
    "\n",
    "def _parse_datetime(val: str) -> pd.Timestamp:\n",
    "    return pd.to_datetime(val, errors=\"coerce\")\n",
    "\n",
    "def load_patient_csv(path: str) -> pd.DataFrame:\n",
    "    date_cols = [\"ECG_DATETIME\", \"ADMITTIME\", \"DISCHTIME\", \"DEATHTIME\", \"DOB\"]\n",
    "    converters = {\n",
    "        **{c: _parse_datetime for c in date_cols},\n",
    "        \"ICD9_CODE\": _parse_icd9,\n",
    "        \"ECG_DATETIME_y\": _parse_ecg_list,\n",
    "    }\n",
    "    df = pd.read_csv(path, converters=converters)\n",
    "\n",
    "    # age 若為 object → 轉 numeric\n",
    "    if df[\"age\"].dtype == \"O\":\n",
    "        df.loc[:, \"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "alive_42731 = load_patient_csv(\".\\experiment_data_from_yuran\\活_ICD9_427_20250211_with_age.csv\")\n",
    "dead_42731 = load_patient_csv(\".\\experiment_data_from_yuran\\死_ICD9_427_20250211_with_age.csv\")\n",
    "\n",
    "print(alive_42731.info())\n",
    "print(dead_42731.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23463ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover all alive :set()\n",
      "Total : 361, subject id: 361\n",
      "Empty DataFrame\n",
      "Columns: [index, SUBJECT_ID, ECG_DATETIME, HADM_ID, ICD9_CODE, ADMITTIME, DISCHTIME, DEATHTIME, ECG_DATETIME_y, GENDER, DOB, wave_id, age, death]\n",
      "Index: []\n",
      "{47233, 82565, 20742, 21771, 40460, 24461, 1038, 81807, 75793, 76435, 30484, 12821, 72467, 88851, 25115, 90269, 43422, 78238, 80030, 75170, 76196, 8105, 20013, 92846, 12461, 62254, 63028, 59457, 65732, 29511, 49739, 91853, 59215, 50385, 32210, 16210, 73686, 83288, 5343, 15079, 95849, 15470, 82159, 52592, 58993, 55922, 57208, 24825, 23034, 75772}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Surv and alive_42731 分析\n",
    "from datetime import timedelta\n",
    "alive_42731_match = alive_42731[alive_42731['SUBJECT_ID'].isin(alive_set & surv_set)].reset_index()\n",
    "\n",
    "alive_42731_set = set(alive_42731_match['SUBJECT_ID'].to_list())\n",
    "print(f\"Cover all alive :{(alive_set & surv_set)- alive_42731_set}\")\n",
    "print(f\"Total : {len(alive_42731_match)}, subject id: {alive_42731_match['SUBJECT_ID'].nunique()}\")\n",
    "\n",
    "surv_stage2_filtered['T0'] = pd.to_datetime(surv_stage2_filtered['T0'])\n",
    "tolerance = timedelta(seconds=60)\n",
    "\n",
    "is_same_time = []\n",
    "\n",
    "for _, row in alive_42731_match.iterrows():\n",
    "    subject_id = row['SUBJECT_ID']\n",
    "    ecg_time = pd.to_datetime(row['ECG_DATETIME'], errors='coerce')\n",
    "\n",
    "    match_times = surv_stage2_filtered[\n",
    "        surv_stage2_filtered['SUBJECT_ID'] == subject_id\n",
    "    ]['T0']\n",
    "\n",
    "    # 檢查是否存在任一時間差在 60 秒內\n",
    "    is_match = ((match_times - ecg_time).abs() <= tolerance).any()\n",
    "    is_same_time.append(is_match)\n",
    "\n",
    "# 過濾不符合條件的\n",
    "alive_42731_not_match = alive_42731_match[~pd.Series(is_same_time).values]\n",
    "print(alive_42731_not_match)\n",
    "\n",
    "print(surv_set-set(alive_42731['SUBJECT_ID'].to_list()))\n",
    "\n",
    "print(set(alive_42731['SUBJECT_ID'].to_list()) & set(dead_42731['SUBJECT_ID'].to_list()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a19a66c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover all alive :set()\n",
      "Total : 96, subject id: 96\n",
      "Empty DataFrame\n",
      "Columns: [index, SUBJECT_ID, ECG_DATETIME, HADM_ID, ICD9_CODE, ADMITTIME, DISCHTIME, DEATHTIME, ECG_DATETIME_y, GENDER, DOB, wave_id, age, death]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Mort and dead_42731 分析\n",
    "dead_42731_match = dead_42731[dead_42731['SUBJECT_ID'].isin(dead_set & mort_set)].reset_index()\n",
    "\n",
    "dead_42731_set = set(dead_42731_match['SUBJECT_ID'].to_list())\n",
    "print(f\"Cover all alive :{(dead_set & mort_set)- dead_42731_set}\")\n",
    "print(f\"Total : {len(dead_42731_match)}, subject id: {dead_42731_match['SUBJECT_ID'].nunique()}\")\n",
    "\n",
    "mort_stage2_filtered['T0'] = pd.to_datetime(mort_stage2_filtered['T0'])\n",
    "tolerance = timedelta(seconds=60)\n",
    "\n",
    "is_same_time = []\n",
    "\n",
    "for _, row in dead_42731_match.iterrows():\n",
    "    subject_id = row['SUBJECT_ID']\n",
    "    ecg_time = pd.to_datetime(row['ECG_DATETIME'], errors='coerce')\n",
    "\n",
    "    match_times = mort_stage2_filtered[\n",
    "        mort_stage2_filtered['SUBJECT_ID'] == subject_id\n",
    "    ]['T0']\n",
    "\n",
    "    # 檢查是否存在任一時間差在 60 秒內\n",
    "    is_match = ((match_times - ecg_time).abs() <= tolerance).any()\n",
    "    is_same_time.append(is_match)\n",
    "\n",
    "# 過濾不符合條件的\n",
    "dead_42731_not_match = dead_42731_match[~pd.Series(is_same_time).values]\n",
    "print(dead_42731_not_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4667bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 {47233, 82565, 20742, 21771, 40460, 24461, 1038, 81807, 75793, 76435, 30484, 12821, 72467, 88851, 25115, 90269, 43422, 78238, 80030, 75170, 76196, 8105, 20013, 92846, 12461, 62254, 63028, 59457, 65732, 29511, 49739, 91853, 59215, 50385, 32210, 16210, 73686, 83288, 5343, 15079, 95849, 15470, 82159, 52592, 58993, 55922, 57208, 24825, 23034, 75772}\n"
     ]
    }
   ],
   "source": [
    "# 劃分出不在 活_ICD9_427 底下的紀錄\n",
    "not_in_427 = set(surv_stage2_filtered_with_wave_id['SUBJECT_ID'].to_list()) - set(alive_42731['SUBJECT_ID'].to_list())\n",
    "\n",
    "print(len(not_in_427),not_in_427)\n",
    "surv_stage2_filtered_with_wave_id_not_in_427 = surv_stage2_filtered_with_wave_id[surv_stage2_filtered_with_wave_id['SUBJECT_ID'].isin(not_in_427)]\n",
    "surv_stage2_filtered_with_wave_id_not_in_427.to_csv(os.path.join(LOGS,\"surv_stage2_filtered_with_wave_id_not_in_427.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581dace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039 {65537, 10241, 51202, 75779, 61441, 96259, 40967, 96261, 83981, 30733, 16399, 10257, 63512, 43033, 86041, 79900, 43037, 45088, 24609, 53282, 22565, 63525, 98344, 4136, 92203, 69675, 90158, 94256, 69681, 77873, 43060, 88117, 30775, 69693, 96321, 18498, 67653, 59462, 86086, 63559, 63563, 59469, 69709, 4175, 8274, 4180, 6229, 98390, 22616, 94297, 82010, 18524, 94301, 53342, 63582, 71774, 47203, 67684, 57445, 82021, 49255, 96361, 53355, 2157, 26734, 12400, 47216, 22642, 14458, 92287, 98434, 45186, 63621, 28808, 22664, 73868, 20620, 45199, 57489, 77975, 26781, 57511, 65703, 4266, 8363, 51377, 86193, 55473, 71857, 55477, 18614, 10423, 63669, 78010, 96445, 98494, 6335, 71872, 12482, 82115, 75972, 14532, 41163, 22731, 47309, 88269, 98517, 214, 63701, 61656, 217, 65753, 67803, 61658, 14551, 43233, 76001, 73955, 49380, 28897, 78050, 86245, 41194, 84206, 69871, 22766, 65779, 41204, 45300, 63733, 22774, 98555, 22782, 92415, 41217, 76034, 82179, 98565, 262, 63750, 51466, 63755, 80142, 4369, 90389, 12565, 24856, 76058, 20763, 80154, 10525, 63771, 63773, 43296, 76066, 14626, 53541, 41254, 10534, 90410, 18733, 61742, 86318, 47406, 59701, 96567, 31034, 20795, 96574, 76096, 55616, 72000, 82244, 4420, 69956, 31051, 57678, 96592, 31057, 72017, 98643, 76116, 10581, 86355, 96594, 47444, 24923, 2395, 18786, 26978, 53612, 59757, 86381, 14702, 47473, 12663, 22904, 20860, 4477, 65925, 78214, 2442, 70026, 59788, 86411, 78221, 29073, 18837, 24984, 41373, 6561, 2467, 45477, 84392, 16810, 10667, 55722, 41389, 98733, 29102, 27060, 16821, 94645, 12727, 25016, 59833, 51642, 45495, 20922, 80313, 96697, 14780, 92613, 61898, 51660, 94669, 25039, 43472, 98769, 2514, 80339, 57815, 31191, 72151, 63961, 53724, 96732, 68065, 49635, 53731, 23015, 72170, 68075, 2549, 74230, 20984, 84478, 61956, 51722, 47634, 8723, 66067, 49685, 23061, 96791, 92698, 61980, 68126, 12831, 94753, 82466, 80423, 55849, 47660, 23085, 94768, 57905, 14899, 18998, 27192, 59960, 86585, 23097, 86589, 98878, 23105, 90690, 14914, 78410, 53835, 25168, 43601, 62032, 64082, 92764, 23132, 47709, 78431, 47715, 10852, 47718, 12903, 78441, 74346, 57964, 64112, 625, 53875, 53876, 94838, 94840, 88696, 17018, 94847, 47749, 86662, 98957, 98959, 98961, 27282, 41619, 68242, 29336, 82585, 60057, 84633, 98973, 88734, 29343, 86692, 58022, 88747, 10924, 15021, 98991, 70319, 82609, 94896, 53939, 4788, 19125, 695, 43705, 70329, 2747, 76476, 86719, 2754, 99011, 708, 4802, 21187, 4807, 96965, 80586, 49872, 17105, 43729, 60115, 47827, 88790, 49879, 43738, 90843, 99038, 735, 51936, 25313, 60130, 25317, 51942, 92903, 76520, 78565, 86757, 64230, 66288, 97013, 72439, 99064, 45816, 13049, 11003, 13052, 74493, 17152, 58113, 76544, 94977, 97028, 66311, 72459, 76557, 84749, 45838, 99088, 13071, 74514, 19218, 51986, 94993, 66326, 43798, 29463, 64280, 23321, 99102, 27423, 49955, 11043, 90917, 29477, 80675, 84776, 62248, 45866, 68401, 74546, 76594, 70451, 6967, 54073, 76602, 9021, 66365, 17218, 52039, 31559, 21321, 82765, 64336, 849, 23380, 43866, 45914, 58205, 70494, 19297, 68453, 64361, 25452, 90990, 60272, 45936, 74610, 95090, 23413, 72571, 58242, 95107, 48006, 58247, 43911, 54153, 56201, 15243, 19342, 74639, 82831, 99216, 23440, 72592, 17300, 27540, 43926, 91031, 88976, 88982, 41882, 76698, 64411, 58270, 82847, 31648, 13218, 23459, 2981, 50089, 41902, 19375, 15279, 23474, 54195, 2996, 54197, 76726, 11191, 60343, 86965, 89012, 48058, 93117, 50110, 27585, 15298, 31684, 58310, 21447, 21448, 48076, 19405, 54221, 62415, 97232, 82898, 68564, 23510, 46041, 9178, 99291, 29660, 29664, 66530, 60389, 52199, 93159, 21484, 74733, 62447, 82928, 1012, 80885, 5114, 68605, 76800, 46080, 17412, 5126, 60424, 58377, 66571, 44044, 56333, 48145, 25621, 15382, 93208, 44058, 74779, 23580, 23584, 91169, 23594, 27691, 7213, 64557, 23599, 1072, 95282, 42035, 21561, 56378, 89148, 95294, 91200, 23627, 46156, 72779, 85071, 99412, 70740, 48212, 72790, 93272, 17497, 70745, 89179, 66654, 9311, 44128, 74851, 78948, 23652, 99439, 9332, 68724, 46197, 1144, 99448, 23674, 56443, 54397, 21630, 48253, 29826, 52355, 66692, 78979, 52363, 62603, 95373, 3214, 81041, 42130, 66717, 46237, 21663, 87203, 70822, 81063, 19624, 97448, 29866, 91309, 62641, 89265, 85171, 21683, 15538, 9398, 46264, 83129, 79032, 5307, 46268, 93378, 95426, 70854, 87239, 21710, 15567, 15569, 99545, 15583, 93411, 95460, 99560, 7400, 87275, 99564, 52462, 79089, 85235, 66807, 29946, 54523, 62715, 62717, 62721, 46339, 15619, 48390, 58631, 44298, 54541, 9486, 32013, 48397, 75029, 15637, 3351, 25882, 75034, 99616, 1313, 3365, 85286, 93479, 46373, 72999, 66859, 40236, 68909, 70957, 97581, 95536, 7470, 68915, 68916, 19765, 95542, 81203, 79163, 99645, 70974, 99650, 32067, 42310, 42311, 83272, 91463, 52550, 54600, 30026, 81229, 77135, 44369, 54609, 32084, 15701, 23893, 32085, 93528, 17753, 99674, 68956, 21857, 21860, 66919, 85352, 50537, 7533, 95603, 89459, 42360, 44408, 11641, 95609, 83324, 99708, 56697, 85375, 46467, 62854, 28039, 46471, 1418, 17803, 85389, 40334, 81295, 85393, 75155, 54675, 21910, 75160, 87450, 60829, 17822, 73118, 28065, 54690, 44454, 46502, 26024, 1449, 58793, 77227, 99759, 11698, 79283, 44468, 28085, 69047, 3512, 13752, 89528, 91579, 3515, 69052, 13759, 9664, 99776, 46527, 56772, 93638, 62919, 95688, 62926, 54735, 11728, 54736, 50643, 99796, 9685, 21975, 52696, 50649, 69082, 89565, 56802, 93667, 64994, 5606, 73190, 91635, 44532, 77301, 99830, 1528, 17913, 79352, 97786, 48637, 24063, 48640, 81408, 9732, 95754, 15885, 50703, 56849, 91669, 60949, 22039, 26136, 9753, 44570, 1563, 52762, 93722, 52766, 19999, 48666, 54817, 32288, 48674, 50729, 60969, 52778, 97834, 48688, 52791, 17976, 50744, 58938, 87608, 71230, 85575, 67149, 11855, 99922, 93784, 44633, 22104, 75355, 98016, 71262, 63074, 89698, 50793, 3695, 56947, 54900, 32373, 79480, 44666, 50816, 71296, 81536, 63107, 97924, 89734, 63116, 16013, 89742, 50832, 69265, 13970, 7825, 93847, 63131, 3744, 71328, 7842, 56996, 42663, 67239, 89772, 40624, 14005, 3768, 30393, 5821, 32447, 50880, 57023, 97984, 79556, 50885, 52934, 50888, 87754, 95948, 46797, 42702, 77520, 22225, 63187, 14036, 52952, 16088, 32474, 44763, 61149, 59102, 69344, 42721, 28386, 50915, 79584, 46817, 22242, 63201, 30436, 79589, 87789, 65263, 44784, 40689, 55027, 73460, 75509, 44789, 30457, 16122, 69371, 85757, 98046, 59135, 28416, 14079, 9987, 63237, 9993, 26377, 77578, 87817, 26381, 16139, 96015, 48910, 61201, 67348, 30486, 61207, 53020, 7965, 40736, 16164, 75557, 91946, 53036, 10030, 3886, 67377, 89906, 10042, 73530, 12094, 46910, 73537, 71491, 16196, 94021, 73540, 18248, 51017, 12110, 30542, 12113, 67415, 75607, 71513, 65370, 22364, 40797, 26467, 20324, 51045, 81766, 55143, 1900, 22383, 67446, 77686, 51064, 30582, 22393, 51072, 49024, 8070, 46984, 30606, 73615, 53136, 83857, 69522, 87953, 92052, 1941, 67477, 94103, 22418, 6039, 16279, 1949, 32670, 92063, 77729, 90020, 87975, 10152, 8109, 83887, 44976, 51121, 4018, 6063, 18357, 6070, 53176, 87992, 69563, 22461, 6078, 88003, 83908, 57283, 6090, 81866, 30669, 88013, 16337, 81875, 94164, 69591, 63447, 14298, 4059, 22491, 57308, 81885, 22495, 49118, 96225, 26594, 57314, 71652, 81893, 12267, 24556, 18413, 77807, 94195, 28660, 47093, 24567, 20479}\n",
      "0         214\n",
      "1         217\n",
      "2         262\n",
      "4         625\n",
      "5         695\n",
      "        ...  \n",
      "1445    99759\n",
      "1446    99776\n",
      "1447    99796\n",
      "1448    99830\n",
      "1449    99922\n",
      "Name: SUBJECT_ID, Length: 1039, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "in_427_not_in_final = (set(surv_stage2_filtered_with_wave_id['SUBJECT_ID'].to_list()) & set(alive_42731['SUBJECT_ID'].to_list())) - alive_set\n",
    "print(len(in_427_not_in_final),in_427_not_in_final)\n",
    "surv_stage2_filtered_with_wave_id_addition = surv_stage2_filtered_with_wave_id[surv_stage2_filtered_with_wave_id['SUBJECT_ID'].isin(in_427_not_in_final)]\n",
    "print(surv_stage2_filtered_with_wave_id_addition['SUBJECT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SUBJECT_ID  HADM_ID  ICUSTAY_ID              INTIME             OUTTIME  \\\n",
      "0            214   197273      241941 2188-10-28 21:26:20 2188-11-03 11:45:06   \n",
      "1            217   155173      226300 2126-09-30 10:59:50 2126-10-01 12:16:46   \n",
      "2            262   106019      243312 2153-09-25 18:02:24 2153-09-27 13:59:18   \n",
      "4            625   145523      274000 2178-04-24 21:30:15 2178-05-03 19:11:31   \n",
      "5            695   177128      289542 2178-08-05 07:39:02 2178-08-13 14:07:01   \n",
      "...          ...      ...         ...                 ...                 ...   \n",
      "1445       99759   157932      216511 2161-03-10 09:43:03 2161-03-11 16:52:32   \n",
      "1446       99776   136231      262109 2171-07-08 04:15:10 2171-07-18 17:15:38   \n",
      "1447       99796   144804      285715 2115-02-12 09:56:20 2115-02-13 17:03:25   \n",
      "1448       99830   176834      211489 2187-08-20 20:46:45 2187-09-04 15:48:21   \n",
      "1449       99922   123563      259919 2107-04-07 10:52:03 2107-04-08 10:55:22   \n",
      "\n",
      "               ADMITTIME           DISCHTIME  DEATHTIME  HOSPITAL_EXPIRE_FLAG  \\\n",
      "0    2188-10-06 23:56:00 2188-11-04 11:40:00        NaN                     0   \n",
      "1    2126-09-30 07:15:00 2126-10-05 11:24:00        NaN                     0   \n",
      "2    2153-09-25 18:01:00 2153-09-28 18:48:00        NaN                     0   \n",
      "4    2178-04-24 21:29:00 2178-05-06 17:30:00        NaN                     0   \n",
      "5    2178-08-05 07:38:00 2178-08-13 14:00:00        NaN                     0   \n",
      "...                  ...                 ...        ...                   ...   \n",
      "1445 2161-03-09 07:15:00 2161-03-14 14:40:00        NaN                     0   \n",
      "1446 2171-07-08 04:14:00 2171-07-23 16:20:00        NaN                     0   \n",
      "1447 2115-02-11 17:27:00 2115-02-19 01:30:00        NaN                     0   \n",
      "1448 2187-08-20 20:46:00 2187-09-14 10:45:00        NaN                     0   \n",
      "1449 2107-04-07 07:15:00 2107-04-11 17:16:00        NaN                     0   \n",
      "\n",
      "      HAS_AF  ...   FOLDER                    HEADER                      T0  \\\n",
      "0        1.0  ...  p000214  p000214-2188-10-28-22-02 2188-10-28 22:02:00.745   \n",
      "1        1.0  ...  p000217  p000217-2126-09-30-12-28 2126-09-30 12:28:39.077   \n",
      "2        1.0  ...  p000262  p000262-2153-09-25-18-06 2153-09-25 18:06:28.360   \n",
      "4        1.0  ...  p000625  p000625-2178-04-27-10-42 2178-04-27 10:42:05.758   \n",
      "5        1.0  ...  p000695  p000695-2178-08-07-14-33 2178-08-07 14:33:25.314   \n",
      "...      ...  ...      ...                       ...                     ...   \n",
      "1445     1.0  ...  p099759  p099759-2161-03-10-16-38 2161-03-10 16:38:25.000   \n",
      "1446     1.0  ...  p099776  p099776-2171-07-09-15-30 2171-07-09 15:30:06.509   \n",
      "1447     1.0  ...  p099796  p099796-2115-02-12-14-02 2115-02-12 14:02:45.096   \n",
      "1448     1.0  ...  p099830  p099830-2187-08-29-13-01 2187-08-29 13:01:12.000   \n",
      "1449     1.0  ...  p099922  p099922-2107-04-07-12-17 2107-04-07 12:17:34.000   \n",
      "\n",
      "                           T1                T1_lead2 Total_lead2_sec  \\\n",
      "0     2188-10-30 09:42:10.537 2188-10-30 09:42:10.537      128100.000   \n",
      "1     2126-10-01 12:02:43.133 2126-10-01 12:02:43.133       84840.000   \n",
      "2     2153-09-27 00:40:16.360 2153-09-27 00:40:16.360      110028.000   \n",
      "4     2178-05-03 18:19:33.222 2178-04-30 23:34:12.638      298440.000   \n",
      "5     2178-08-11 20:03:57.546 2178-08-11 20:03:57.546      257900.000   \n",
      "...                       ...                     ...             ...   \n",
      "1445  2161-03-11 16:38:25.000 2161-03-11 16:38:25.000       86396.000   \n",
      "1446  2171-07-11 21:28:28.509 2171-07-11 21:28:28.509      192142.000   \n",
      "1447  2115-02-13 16:52:46.000 2115-02-13 16:52:46.000       96540.904   \n",
      "1448  2187-09-04 15:20:12.000 2187-09-04 15:20:12.000      524070.000   \n",
      "1449  2107-04-08 10:47:34.000 2107-04-08 10:47:34.000       80895.000   \n",
      "\n",
      "             DOB age  AGE_UNDER_125  wave_id  \n",
      "0     2125-04-29  63           True  3502927  \n",
      "1     2058-07-01  68           True  3804320  \n",
      "2     2090-01-05  63           True  3196146  \n",
      "4     2118-06-04  60           True  3522989  \n",
      "5     2093-05-14  85           True  3976294  \n",
      "...          ...  ..            ...      ...  \n",
      "1445  2079-08-22  82           True  3708908  \n",
      "1446  2115-02-01  56           True  3031916  \n",
      "1447  2052-03-25  63           True  3151288  \n",
      "1448  2138-05-11  49           True  3162585  \n",
      "1449  2037-12-25  70           True  3408272  \n",
      "\n",
      "[937 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_185756\\4196850454.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surv_stage2_filtered_with_wave_id_addition['T1_lead2'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['T1_lead2'])\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_185756\\4196850454.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surv_stage2_filtered_with_wave_id_addition['OUTTIME'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['OUTTIME'])\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_185756\\4196850454.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surv_stage2_filtered_with_wave_id_addition['DISCHTIME'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['DISCHTIME'])\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_185756\\4196850454.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surv_stage2_filtered_with_wave_id_addition['T0'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['T0'])\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_185756\\4196850454.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surv_stage2_filtered_with_wave_id_addition['INTIME'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['INTIME'])\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_185756\\4196850454.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surv_stage2_filtered_with_wave_id_addition['ADMITTIME'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['ADMITTIME'])\n"
     ]
    }
   ],
   "source": [
    "surv_stage2_filtered_with_wave_id_addition['T1_lead2'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['T1_lead2'])\n",
    "surv_stage2_filtered_with_wave_id_addition['OUTTIME'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['OUTTIME'])\n",
    "surv_stage2_filtered_with_wave_id_addition['DISCHTIME'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['DISCHTIME'])\n",
    "surv_stage2_filtered_with_wave_id_addition['T0'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['T0'])\n",
    "surv_stage2_filtered_with_wave_id_addition['INTIME'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['INTIME'])\n",
    "surv_stage2_filtered_with_wave_id_addition['ADMITTIME'] = pd.to_datetime(surv_stage2_filtered_with_wave_id_addition['ADMITTIME'])\n",
    "\n",
    "\n",
    "mask = (\n",
    "    (surv_stage2_filtered_with_wave_id_addition['T1_lead2'] <= surv_stage2_filtered_with_wave_id_addition['OUTTIME'])&\n",
    "    (surv_stage2_filtered_with_wave_id_addition['T1_lead2'] <= surv_stage2_filtered_with_wave_id_addition['DISCHTIME'])&\n",
    "    (surv_stage2_filtered_with_wave_id_addition['INTIME'] <= surv_stage2_filtered_with_wave_id_addition['T0'])&\n",
    "    (surv_stage2_filtered_with_wave_id_addition['ADMITTIME']<= surv_stage2_filtered_with_wave_id_addition['T0'])\n",
    "\n",
    ")   \n",
    "surv_stage2_filtered_with_wave_id_addition=surv_stage2_filtered_with_wave_id_addition[mask]\n",
    "print(surv_stage2_filtered_with_wave_id_addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b360771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index SUBJECT_ID HADM_ID  wave_id_test\n",
      "0      0         30  104557       3524877\n",
      "1      1         79  181542       3887555\n",
      "2      2         85  112077       3647298\n",
      "3      3        194  124794       3400942\n",
      "4      4        214  197273       3502927\n",
      "有 NaN 的筆數： 6\n",
      "    SUBJECT_ID HADM_ID  wave_id_test\n",
      "72        8109  192031           NaN\n",
      "152      16122  166498           NaN\n",
      "265      25313  148253           NaN\n",
      "300      29660  167837           NaN\n",
      "512      54197  154990           NaN\n",
      "796      79556  148982           NaN\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1039 entries, 0 to 1038\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   SUBJECT_ID            1039 non-null   object        \n",
      " 1   HADM_ID               1039 non-null   object        \n",
      " 2   ICUSTAY_ID            1039 non-null   int64         \n",
      " 3   INTIME                1039 non-null   datetime64[ns]\n",
      " 4   OUTTIME               1039 non-null   datetime64[ns]\n",
      " 5   ADMITTIME             1039 non-null   datetime64[ns]\n",
      " 6   DISCHTIME             1039 non-null   datetime64[ns]\n",
      " 7   DEATHTIME             0 non-null      float64       \n",
      " 8   HOSPITAL_EXPIRE_FLAG  1039 non-null   int64         \n",
      " 9   HAS_AF                1039 non-null   float64       \n",
      " 10  PREFIX                1039 non-null   object        \n",
      " 11  FOLDER                1039 non-null   object        \n",
      " 12  HEADER                1039 non-null   object        \n",
      " 13  T0                    1039 non-null   datetime64[ns]\n",
      " 14  T1                    1039 non-null   object        \n",
      " 15  T1_lead2              1039 non-null   datetime64[ns]\n",
      " 16  Total_lead2_sec       1039 non-null   float64       \n",
      " 17  DOB                   1039 non-null   object        \n",
      " 18  age                   1039 non-null   int64         \n",
      " 19  AGE_UNDER_125         1039 non-null   bool          \n",
      " 20  wave_id               1039 non-null   int64         \n",
      " 21  index                 1033 non-null   float64       \n",
      " 22  wave_id_test          1039 non-null   int64         \n",
      "dtypes: bool(1), datetime64[ns](6), float64(4), int64(5), object(7)\n",
      "memory usage: 179.7+ KB\n",
      "None\n",
      "     SUBJECT_ID HADM_ID  ICUSTAY_ID              INTIME             OUTTIME  \\\n",
      "0           214  197273      241941 2188-10-28 21:26:20 2188-11-03 11:45:06   \n",
      "1           217  155173      226300 2126-09-30 10:59:50 2126-10-01 12:16:46   \n",
      "2           262  106019      243312 2153-09-25 18:02:24 2153-09-27 13:59:18   \n",
      "4           695  177128      289542 2178-08-05 07:39:02 2178-08-13 14:07:01   \n",
      "5           708  168790      246739 2133-05-21 10:21:46 2133-05-26 11:35:48   \n",
      "...         ...     ...         ...                 ...                 ...   \n",
      "1034      99759  157932      216511 2161-03-10 09:43:03 2161-03-11 16:52:32   \n",
      "1035      99776  136231      262109 2171-07-08 04:15:10 2171-07-18 17:15:38   \n",
      "1036      99796  144804      285715 2115-02-12 09:56:20 2115-02-13 17:03:25   \n",
      "1037      99830  176834      211489 2187-08-20 20:46:45 2187-09-04 15:48:21   \n",
      "1038      99922  123563      259919 2107-04-07 10:52:03 2107-04-08 10:55:22   \n",
      "\n",
      "               ADMITTIME           DISCHTIME  DEATHTIME  HOSPITAL_EXPIRE_FLAG  \\\n",
      "0    2188-10-06 23:56:00 2188-11-04 11:40:00        NaN                     0   \n",
      "1    2126-09-30 07:15:00 2126-10-05 11:24:00        NaN                     0   \n",
      "2    2153-09-25 18:01:00 2153-09-28 18:48:00        NaN                     0   \n",
      "4    2178-08-05 07:38:00 2178-08-13 14:00:00        NaN                     0   \n",
      "5    2133-05-21 08:00:00 2133-05-28 11:10:00        NaN                     0   \n",
      "...                  ...                 ...        ...                   ...   \n",
      "1034 2161-03-09 07:15:00 2161-03-14 14:40:00        NaN                     0   \n",
      "1035 2171-07-08 04:14:00 2171-07-23 16:20:00        NaN                     0   \n",
      "1036 2115-02-11 17:27:00 2115-02-19 01:30:00        NaN                     0   \n",
      "1037 2187-08-20 20:46:00 2187-09-14 10:45:00        NaN                     0   \n",
      "1038 2107-04-07 07:15:00 2107-04-11 17:16:00        NaN                     0   \n",
      "\n",
      "      HAS_AF  ...                      T0                       T1  \\\n",
      "0        1.0  ... 2188-10-28 22:02:00.745  2188-10-30 09:42:10.537   \n",
      "1        1.0  ... 2126-09-30 12:28:39.077  2126-10-01 12:02:43.133   \n",
      "2        1.0  ... 2153-09-25 18:06:28.360  2153-09-27 00:40:16.360   \n",
      "4        1.0  ... 2178-08-07 14:33:25.314  2178-08-11 20:03:57.546   \n",
      "5        1.0  ... 2133-05-21 12:43:40.225  2133-05-26 11:18:52.481   \n",
      "...      ...  ...                     ...                      ...   \n",
      "1034     1.0  ... 2161-03-10 16:38:25.000  2161-03-11 16:38:25.000   \n",
      "1035     1.0  ... 2171-07-09 15:30:06.509  2171-07-11 21:28:28.509   \n",
      "1036     1.0  ... 2115-02-12 14:02:45.096  2115-02-13 16:52:46.000   \n",
      "1037     1.0  ... 2187-08-29 13:01:12.000  2187-09-04 15:20:12.000   \n",
      "1038     1.0  ... 2107-04-07 12:17:34.000  2107-04-08 10:47:34.000   \n",
      "\n",
      "                    T1_lead2 Total_lead2_sec         DOB age  AGE_UNDER_125  \\\n",
      "0    2188-10-30 09:42:10.537      128100.000  2125-04-29  63           True   \n",
      "1    2126-10-01 12:02:43.133       84840.000  2058-07-01  68           True   \n",
      "2    2153-09-27 00:40:16.360      110028.000  2090-01-05  63           True   \n",
      "4    2178-08-11 20:03:57.546      257900.000  2093-05-14  85           True   \n",
      "5    2133-05-26 06:00:52.481      368640.000  2061-02-17  72           True   \n",
      "...                      ...             ...         ...  ..            ...   \n",
      "1034 2161-03-11 16:38:25.000       86396.000  2079-08-22  82           True   \n",
      "1035 2171-07-11 21:28:28.509      192142.000  2115-02-01  56           True   \n",
      "1036 2115-02-13 16:52:46.000       96540.904  2052-03-25  63           True   \n",
      "1037 2187-09-04 15:20:12.000      524070.000  2138-05-11  49           True   \n",
      "1038 2107-04-08 10:47:34.000       80895.000  2037-12-25  70           True   \n",
      "\n",
      "      wave_id   index  wave_id_test  \n",
      "0     3502927     4.0       3502927  \n",
      "1     3804320     5.0       3804320  \n",
      "2     3196146     7.0       3196146  \n",
      "4     3976294    20.0       3976294  \n",
      "5     3500279    21.0       3500279  \n",
      "...       ...     ...           ...  \n",
      "1034  3708908  2784.0       3708908  \n",
      "1035  3031916  2785.0       3031916  \n",
      "1036  3151288  2786.0       3151288  \n",
      "1037  3162585  2787.0       3162585  \n",
      "1038  3408272  2791.0       3408272  \n",
      "\n",
      "[953 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_185756\\3449582169.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surv_stage2_filtered_with_wave_id_addition[col] = surv_stage2_filtered_with_wave_id_addition[col].astype(str).str.strip()\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_185756\\3449582169.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surv_stage2_filtered_with_wave_id_addition[col] = surv_stage2_filtered_with_wave_id_addition[col].astype(str).str.strip()\n"
     ]
    }
   ],
   "source": [
    "cols = ['SUBJECT_ID','HADM_ID','wave_id']\n",
    "modified_alive_427 = load_patient_csv(\".\\experiment_data_from_yuran\\modified_活人_ICD9_427_20250211_with_age+TIME_LENGTH.csv\")\n",
    "modified_alive_427 = modified_alive_427[cols]\n",
    "modified_alive_427_rename = modified_alive_427.rename(columns={\n",
    "    'wave_id':'wave_id_test'\n",
    "}).reset_index()\n",
    "\n",
    "# Step 1: 統一型別 + 去除空白\n",
    "for col in ['SUBJECT_ID', 'HADM_ID']:\n",
    "    modified_alive_427_rename[col] = modified_alive_427_rename[col].astype(str).str.strip()\n",
    "    surv_stage2_filtered_with_wave_id_addition[col] = surv_stage2_filtered_with_wave_id_addition[col].astype(str).str.strip()\n",
    "\n",
    "modified_alive_427_rename['wave_id_test'] = modified_alive_427_rename['wave_id_test'].astype(int)\n",
    "print(modified_alive_427_rename.head())\n",
    "surv_stage2_filtered_with_wave_id_addition_merge = surv_stage2_filtered_with_wave_id_addition.merge(\n",
    "    modified_alive_427_rename,\n",
    "    on=['SUBJECT_ID','HADM_ID'],\n",
    "    how=\"left\"\n",
    ")\n",
    "# 檢查有哪些是空值\n",
    "null_rows = surv_stage2_filtered_with_wave_id_addition_merge[surv_stage2_filtered_with_wave_id_addition_merge['wave_id_test'].isnull()]\n",
    "print(\"有 NaN 的筆數：\", len(null_rows))\n",
    "print(null_rows[['SUBJECT_ID', 'HADM_ID', 'wave_id_test']])\n",
    "\n",
    "surv_stage2_filtered_with_wave_id_addition_merge['wave_id_test'] = (\n",
    "    surv_stage2_filtered_with_wave_id_addition_merge['wave_id_test']\n",
    "    .fillna(-1)  # 用 -1 代表無對應資料\n",
    "    .astype(int)\n",
    ")\n",
    "surv_stage2_filtered_with_wave_id_addition_merge['wave_id'] = surv_stage2_filtered_with_wave_id_addition_merge['wave_id'].astype(int)\n",
    "print(surv_stage2_filtered_with_wave_id_addition_merge.info())\n",
    "\n",
    "\n",
    "mask_equal_wave = (\n",
    "    surv_stage2_filtered_with_wave_id_addition_merge['wave_id'] == (surv_stage2_filtered_with_wave_id_addition_merge['wave_id_test'])\n",
    ")\n",
    "\n",
    "print(surv_stage2_filtered_with_wave_id_addition_merge[mask_equal_wave])\n",
    "surv_stage2_filtered_with_wave_id_addition_merge[mask_equal_wave].to_csv(os.path.join(LOGS, \"surv_stage2_filtered_with_wave_id_427_not_in_final.csv\"),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
